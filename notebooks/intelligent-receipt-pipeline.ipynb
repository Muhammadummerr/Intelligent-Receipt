{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13305430,"sourceType":"datasetVersion","datasetId":8433897},{"sourceId":13437348,"sourceType":"datasetVersion","datasetId":8529033}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Environment Setup","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/muhammadummerr/Intelligent-Receipt.git\n%cd Intelligent-Receipt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-20T12:27:50.585440Z","iopub.execute_input":"2025-10-20T12:27:50.585697Z","iopub.status.idle":"2025-10-20T12:27:51.052085Z","shell.execute_reply.started":"2025-10-20T12:27:50.585669Z","shell.execute_reply":"2025-10-20T12:27:51.051223Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'Intelligent-Receipt'...\nremote: Enumerating objects: 74, done.\u001b[K\nremote: Counting objects: 100% (74/74), done.\u001b[K\nremote: Compressing objects: 100% (51/51), done.\u001b[K\nremote: Total 74 (delta 11), reused 73 (delta 10), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (74/74), 71.20 KiB | 2.85 MiB/s, done.\nResolving deltas: 100% (11/11), done.\n/kaggle/working/Intelligent-Receipt/Intelligent-Receipt\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T11:21:23.352346Z","iopub.execute_input":"2025-10-20T11:21:23.353101Z","iopub.status.idle":"2025-10-20T11:23:22.565931Z","shell.execute_reply.started":"2025-10-20T11:21:23.353072Z","shell.execute_reply":"2025-10-20T11:23:22.565261Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\nRequirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.6.0+cu124)\nCollecting transformers==4.44.2 (from -r requirements.txt (line 7))\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.1.1)\nCollecting accelerate==0.34.2 (from -r requirements.txt (line 9))\n  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\nCollecting evaluate>=0.4.0 (from -r requirements.txt (line 10))\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (1.0.0rc2)\nRequirement already satisfied: Pillow>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (11.3.0)\nRequirement already satisfied: albumentations>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.0.8)\nRequirement already satisfied: opencv-python-headless>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (4.12.0.88)\nRequirement already satisfied: easyocr>=1.7.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (1.7.2)\nCollecting PyMuPDF>=1.24.3 (from -r requirements.txt (line 20))\n  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: python-bidi>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.6.6)\nRequirement already satisfied: shapely>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (2.1.2)\nRequirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (1.26.4)\nRequirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (2.2.3)\nCollecting scikit-learn>=1.4.2 (from -r requirements.txt (line 27))\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: tqdm>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (4.67.1)\nCollecting groq>=0.6.0 (from -r requirements.txt (line 31))\n  Downloading groq-0.32.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: openai>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (1.97.1)\nRequirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (1.1.1)\nRequirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (2.32.5)\nRequirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 37)) (14.1.0)\nRequirement already satisfied: ipywidgets>=8.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 38)) (8.1.5)\nCollecting matplotlib>=3.8.0 (from -r requirements.txt (line 39))\n  Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: timm>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (1.0.19)\nCollecting pathlib>=1.0.1 (from -r requirements.txt (line 43))\n  Downloading pathlib-1.0.1-py3-none-any.whl.metadata (5.1 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r requirements.txt (line 7)) (3.19.1)\nCollecting huggingface-hub>=0.25.0 (from -r requirements.txt (line 11))\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r requirements.txt (line 7)) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r requirements.txt (line 7)) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r requirements.txt (line 7)) (2025.9.18)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2->-r requirements.txt (line 7)) (0.5.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.44.2->-r requirements.txt (line 7))\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.34.2->-r requirements.txt (line 9)) (7.1.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (2025.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 2))\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 2))\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 2))\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->-r requirements.txt (line 2))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->-r requirements.txt (line 2))\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->-r requirements.txt (line 2))\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->-r requirements.txt (line 2))\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->-r requirements.txt (line 2))\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->-r requirements.txt (line 2))\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->-r requirements.txt (line 2))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 2)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 2)) (1.3.0)\nCollecting pyarrow>=21.0.0 (from datasets>=2.19.0->-r requirements.txt (line 8))\n  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->-r requirements.txt (line 8)) (0.4.0)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->-r requirements.txt (line 8)) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.19.0->-r requirements.txt (line 8)) (0.70.16)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->-r requirements.txt (line 11)) (1.1.10)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.4.4->-r requirements.txt (line 15)) (1.15.3)\nRequirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.4.4->-r requirements.txt (line 15)) (2.12.0a1)\nRequirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.4.4->-r requirements.txt (line 15)) (0.0.24)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations>=1.4.4->-r requirements.txt (line 15)) (3.12.5)\nRequirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations>=1.4.4->-r requirements.txt (line 15)) (6.5.0)\nCollecting numpy>=1.26.4 (from -r requirements.txt (line 25))\n  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr>=1.7.2->-r requirements.txt (line 19)) (0.25.2)\nRequirement already satisfied: pyclipper in /usr/local/lib/python3.11/dist-packages (from easyocr>=1.7.2->-r requirements.txt (line 19)) (1.3.0.post6)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from easyocr>=1.7.2->-r requirements.txt (line 19)) (1.13.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->-r requirements.txt (line 26)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->-r requirements.txt (line 26)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->-r requirements.txt (line 26)) (2025.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->-r requirements.txt (line 27)) (1.5.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->-r requirements.txt (line 27)) (3.6.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq>=0.6.0->-r requirements.txt (line 31)) (4.11.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq>=0.6.0->-r requirements.txt (line 31)) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq>=0.6.0->-r requirements.txt (line 31)) (0.28.1)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq>=0.6.0->-r requirements.txt (line 31)) (1.3.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.42.0->-r requirements.txt (line 32)) (0.10.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->-r requirements.txt (line 34)) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->-r requirements.txt (line 34)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->-r requirements.txt (line 34)) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->-r requirements.txt (line 34)) (2025.8.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->-r requirements.txt (line 37)) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->-r requirements.txt (line 37)) (2.19.2)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->-r requirements.txt (line 38)) (0.2.3)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->-r requirements.txt (line 38)) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->-r requirements.txt (line 38)) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->-r requirements.txt (line 38)) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.1->-r requirements.txt (line 38)) (3.0.15)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 39)) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 39)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 39)) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 39)) (1.4.8)\nRequirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.8.0->-r requirements.txt (line 39)) (3.0.9)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.19.0->-r requirements.txt (line 8)) (3.12.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq>=0.6.0->-r requirements.txt (line 31)) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq>=0.6.0->-r requirements.txt (line 31)) (0.16.0)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (3.0.51)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (4.9.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->-r requirements.txt (line 37)) (0.1.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.4.4->-r requirements.txt (line 15)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.37.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.4.4->-r requirements.txt (line 15)) (2.37.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.4.4->-r requirements.txt (line 15)) (0.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->-r requirements.txt (line 26)) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 2)) (3.0.2)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr>=1.7.2->-r requirements.txt (line 19)) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr>=1.7.2->-r requirements.txt (line 19)) (2025.6.11)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr>=1.7.2->-r requirements.txt (line 19)) (0.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.19.0->-r requirements.txt (line 8)) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.19.0->-r requirements.txt (line 8)) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.19.0->-r requirements.txt (line 8)) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.19.0->-r requirements.txt (line 8)) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.19.0->-r requirements.txt (line 8)) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.19.0->-r requirements.txt (line 8)) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.19.0->-r requirements.txt (line 8)) (1.20.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.1->-r requirements.txt (line 38)) (0.2.13)\nDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading groq-0.32.0-py3-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pathlib-1.0.1-py3-none-any.whl (14 kB)\nDownloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pathlib, PyMuPDF, pyarrow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, scikit-learn, nvidia-cusolver-cu12, matplotlib, groq, transformers, evaluate, accelerate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.2\n    Uninstalling matplotlib-3.7.2:\n      Successfully uninstalled matplotlib-3.7.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.9.0\n    Uninstalling accelerate-1.9.0:\n      Successfully uninstalled accelerate-1.9.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed PyMuPDF-1.26.5 accelerate-0.34.2 evaluate-0.4.6 groq-0.32.0 huggingface-hub-0.35.3 matplotlib-3.10.7 numpy-2.2.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pathlib-1.0.1 pyarrow-21.0.0 scikit-learn-1.7.2 tokenizers-0.19.1 transformers-4.44.2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip uninstall -y scikit-learn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T18:18:37.790459Z","iopub.execute_input":"2025-10-19T18:18:37.790757Z","iopub.status.idle":"2025-10-19T18:18:39.903805Z","shell.execute_reply.started":"2025-10-19T18:18:37.790736Z","shell.execute_reply":"2025-10-19T18:18:39.902888Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: scikit-learn 1.2.2\nUninstalling scikit-learn-1.2.2:\n  Successfully uninstalled scikit-learn-1.2.2\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### Train LayoutLMv3 — Receipt Field Extraction","metadata":{}},{"cell_type":"code","source":"%env PYTHONPATH=./src\n\n!python -u -m receipt_ie.models.training.train_layoutlmv3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T18:18:42.646783Z","iopub.execute_input":"2025-10-19T18:18:42.647056Z","iopub.status.idle":"2025-10-19T19:04:11.711688Z","shell.execute_reply.started":"2025-10-19T18:18:42.647034Z","shell.execute_reply":"2025-10-19T19:04:11.710888Z"}},"outputs":[{"name":"stdout","text":"env: PYTHONPATH=./src\n2025-10-19 18:18:47.804569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760897927.827791     214 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760897927.835128     214 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\npreprocessor_config.json: 100%|████████████████| 275/275 [00:00<00:00, 2.14MB/s]\ntokenizer_config.json: 1.14kB [00:00, 6.23MB/s]\nvocab.json: 899kB [00:00, 22.3MB/s]\nmerges.txt: 456kB [00:00, 87.8MB/s]\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nscan-train: 100%|█████████████████████████████| 626/626 [02:09<00:00,  4.85it/s]\nscan-test: 100%|██████████████████████████████| 347/347 [01:15<00:00,  4.62it/s]\n✅ Loaded 973 samples total.\nconfig.json: 100%|█████████████████████████████| 856/856 [00:00<00:00, 5.59MB/s]\nmodel.safetensors: 100%|██████████████████████| 501M/501M [00:02<00:00, 218MB/s]\nSome weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n  0%|                                                  | 0/1940 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 1.4807, 'grad_norm': 34249.0703125, 'learning_rate': 5.154639175257732e-06, 'epoch': 0.51}\n{'loss': 0.0738, 'grad_norm': 31472.369140625, 'learning_rate': 1.5463917525773197e-05, 'epoch': 1.54}\n 10%|████                                    | 195/1940 [06:18<46:34,  1.60s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:13,  3.47it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:18,  2.50it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:20,  2.17it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:21,  2.02it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:22,  1.93it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:22,  1.86it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:03<00:22,  1.85it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:21,  1.82it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:05<00:21,  1.81it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:21,  1.80it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:20,  1.81it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:06<00:19,  1.80it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:19,  1.79it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:07<00:18,  1.80it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:18,  1.79it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:08<00:17,  1.78it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.78it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:10<00:16,  1.79it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:10<00:16,  1.79it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:15,  1.78it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:12<00:17,  1.52it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:16,  1.59it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:13<00:15,  1.64it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:14,  1.68it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:14<00:13,  1.71it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.74it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:15<00:11,  1.75it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:16<00:11,  1.76it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.77it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:17<00:10,  1.78it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.77it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:18<00:08,  1.78it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:18<00:08,  1.78it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:19<00:07,  1.79it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:19<00:07,  1.79it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:20<00:06,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:21<00:06,  1.76it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.77it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:22<00:05,  1.76it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:22<00:04,  1.78it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:23<00:03,  1.77it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:23<00:03,  1.78it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:24<00:02,  1.79it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:25<00:02,  1.78it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:25<00:01,  1.78it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:26<00:01,  1.78it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:26<00:00,  1.87it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.06169375032186508, 'eval_runtime': 27.7588, 'eval_samples_per_second': 7.025, 'eval_steps_per_second': 1.765, 'epoch': 2.0}\n 10%|████                                    | 195/1940 [06:46<46:34,  1.60s/it]\n100%|███████████████████████████████████████████| 49/49 [00:26<00:00,  2.29it/s]\u001b[A\n                                                                                \u001b[A/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0666, 'grad_norm': 13060.4462890625, 'learning_rate': 1.9931271477663232e-05, 'epoch': 2.05}\n{'loss': 0.0594, 'grad_norm': 20594.787109375, 'learning_rate': 1.9358533791523485e-05, 'epoch': 2.56}\n 15%|██████                                  | 292/1940 [09:45<48:08,  1.75s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:12,  3.72it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:17,  2.60it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:20,  2.23it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:21,  2.07it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:21,  1.97it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:21,  1.92it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:03<00:21,  1.87it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:21,  1.86it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:04<00:21,  1.84it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:20,  1.82it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:20,  1.83it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:06<00:19,  1.81it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:22,  1.57it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:08<00:20,  1.64it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:19,  1.69it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:09<00:18,  1.73it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.75it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:10<00:17,  1.75it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:10<00:16,  1.77it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:15,  1.78it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:11<00:15,  1.79it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:14,  1.80it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:12<00:13,  1.80it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:13,  1.80it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:14<00:12,  1.79it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.80it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:15<00:11,  1.81it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:15<00:11,  1.81it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.82it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:16<00:09,  1.81it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.80it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:17<00:08,  1.80it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:18<00:08,  1.81it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:19<00:07,  1.80it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:19<00:07,  1.80it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:20<00:06,  1.77it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:20<00:06,  1.78it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.79it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:21<00:05,  1.80it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:22<00:04,  1.81it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:22<00:03,  1.79it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:23<00:03,  1.79it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:24<00:02,  1.80it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:24<00:02,  1.80it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:25<00:01,  1.81it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:25<00:01,  1.81it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:26<00:00,  1.89it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.05875431001186371, 'eval_runtime': 27.346, 'eval_samples_per_second': 7.131, 'eval_steps_per_second': 1.792, 'epoch': 2.99}\n 15%|██████                                  | 292/1940 [10:13<48:08,  1.75s/it]\n100%|███████████████████████████████████████████| 49/49 [00:26<00:00,  2.32it/s]\u001b[A\n                                                                                \u001b[A/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0587, 'grad_norm': 14376.1416015625, 'learning_rate': 1.8785796105383734e-05, 'epoch': 3.08}\n{'loss': 0.0578, 'grad_norm': 42956.87109375, 'learning_rate': 1.8213058419243987e-05, 'epoch': 3.59}\n 20%|████████                                | 390/1940 [13:14<41:23,  1.60s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:13,  3.49it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:18,  2.46it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:21,  2.10it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:22,  1.98it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:22,  1.90it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:22,  1.85it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:03<00:22,  1.84it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:26,  1.54it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:05<00:24,  1.61it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:22,  1.67it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:21,  1.70it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:07<00:20,  1.73it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:19,  1.75it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:08<00:19,  1.77it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:18,  1.78it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:09<00:18,  1.77it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.78it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:10<00:16,  1.79it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:11<00:16,  1.78it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:15,  1.75it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:12<00:15,  1.76it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:14,  1.77it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:13<00:14,  1.77it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:13,  1.78it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:14<00:12,  1.77it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.78it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:15<00:11,  1.77it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:16<00:11,  1.79it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.78it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:17<00:10,  1.77it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.77it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:18<00:09,  1.76it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:18<00:08,  1.76it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:19<00:07,  1.76it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:20<00:07,  1.77it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:20<00:06,  1.77it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:21<00:06,  1.77it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.75it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:22<00:05,  1.76it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:22<00:04,  1.77it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:23<00:03,  1.78it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:24<00:03,  1.78it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:24<00:02,  1.76it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:25<00:02,  1.76it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:25<00:01,  1.76it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:26<00:01,  1.76it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:26<00:00,  1.84it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.05577876791357994, 'eval_runtime': 27.9139, 'eval_samples_per_second': 6.986, 'eval_steps_per_second': 1.755, 'epoch': 4.0}\n 20%|████████                                | 390/1940 [13:42<41:23,  1.60s/it]\n100%|███████████████████████████████████████████| 49/49 [00:27<00:00,  2.24it/s]\u001b[A\n                                                                                \u001b[A/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.052, 'grad_norm': 16461.701171875, 'learning_rate': 1.764032073310424e-05, 'epoch': 4.1}\n{'loss': 0.051, 'grad_norm': 28310.91015625, 'learning_rate': 1.706758304696449e-05, 'epoch': 4.62}\n 25%|██████████                              | 487/1940 [16:43<44:27,  1.84s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:12,  3.64it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:17,  2.58it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:20,  2.22it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:21,  2.05it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:22,  1.93it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:22,  1.88it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:03<00:22,  1.85it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:21,  1.83it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:05<00:21,  1.83it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:21,  1.80it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:20,  1.82it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:06<00:19,  1.82it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:19,  1.82it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:07<00:18,  1.81it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:18,  1.80it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:08<00:17,  1.80it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.81it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:10<00:16,  1.81it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:10<00:16,  1.80it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:15,  1.81it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:11<00:14,  1.82it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:14,  1.81it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:12<00:13,  1.79it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:13,  1.80it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:13<00:12,  1.80it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.79it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:14<00:11,  1.81it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:15<00:11,  1.80it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.80it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:16<00:09,  1.81it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.82it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:17<00:08,  1.81it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:18<00:08,  1.82it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:18<00:07,  1.82it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:19<00:07,  1.83it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:19<00:06,  1.82it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:20<00:06,  1.81it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.82it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:21<00:04,  1.82it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:22<00:04,  1.80it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:22<00:04,  1.74it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:23<00:03,  1.76it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:23<00:02,  1.78it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:24<00:02,  1.79it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:24<00:01,  1.80it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:25<00:01,  1.79it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:26<00:00,  1.89it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.05243590101599693, 'eval_runtime': 27.1033, 'eval_samples_per_second': 7.195, 'eval_steps_per_second': 1.808, 'epoch': 4.99}\n 25%|██████████                              | 487/1940 [17:10<44:27,  1.84s/it]\n100%|███████████████████████████████████████████| 49/49 [00:26<00:00,  2.31it/s]\u001b[A\n                                                                                \u001b[A/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0503, 'grad_norm': 12698.65234375, 'learning_rate': 1.6494845360824743e-05, 'epoch': 5.13}\n{'loss': 0.0506, 'grad_norm': 19238.083984375, 'learning_rate': 1.5922107674684996e-05, 'epoch': 5.64}\n 30%|████████████                            | 585/1940 [20:10<35:58,  1.59s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:13,  3.58it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:18,  2.53it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:20,  2.20it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:21,  2.06it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:21,  1.97it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:21,  1.92it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:03<00:21,  1.88it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:21,  1.86it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:04<00:21,  1.85it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:21,  1.80it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:20,  1.80it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:06<00:20,  1.79it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:19,  1.81it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:07<00:18,  1.81it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:18,  1.80it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:08<00:17,  1.80it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.81it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:09<00:16,  1.81it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:10<00:16,  1.80it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:15,  1.80it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:11<00:14,  1.80it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:14,  1.80it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:12<00:13,  1.81it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:13,  1.80it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:13<00:12,  1.79it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.80it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:15<00:11,  1.79it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:15<00:11,  1.75it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.78it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:16<00:10,  1.78it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.78it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:17<00:08,  1.79it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:18<00:08,  1.78it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:18<00:07,  1.78it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:19<00:07,  1.79it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:20<00:06,  1.79it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:20<00:06,  1.79it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.80it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:21<00:05,  1.80it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:22<00:04,  1.80it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:22<00:03,  1.80it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:23<00:03,  1.81it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:23<00:02,  1.80it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:24<00:02,  1.80it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:25<00:01,  1.80it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:25<00:01,  1.77it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:26<00:00,  1.87it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.05252404883503914, 'eval_runtime': 27.5074, 'eval_samples_per_second': 7.089, 'eval_steps_per_second': 1.781, 'epoch': 6.0}\n 30%|████████████                            | 585/1940 [20:37<35:58,  1.59s/it]\n100%|███████████████████████████████████████████| 49/49 [00:26<00:00,  2.28it/s]\u001b[A\n                                                                                \u001b[A/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0478, 'grad_norm': 18067.314453125, 'learning_rate': 1.534936998854525e-05, 'epoch': 6.15}\n{'loss': 0.0458, 'grad_norm': 16774.57421875, 'learning_rate': 1.47766323024055e-05, 'epoch': 6.67}\n 35%|██████████████                          | 682/1940 [23:41<38:25,  1.83s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:13,  3.45it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:18,  2.43it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:21,  2.12it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:22,  1.97it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:22,  1.89it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:22,  1.85it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:04<00:22,  1.81it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:22,  1.76it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:05<00:22,  1.76it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:21,  1.76it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:20,  1.77it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:06<00:20,  1.76it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:20,  1.75it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:08<00:19,  1.75it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:18,  1.74it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:09<00:18,  1.75it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.74it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:10<00:17,  1.74it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:10<00:16,  1.74it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:16,  1.73it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:12<00:15,  1.72it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:15,  1.73it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:13<00:14,  1.73it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:13,  1.72it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:14<00:13,  1.72it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.73it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:15<00:12,  1.72it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:16<00:11,  1.73it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.73it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:17<00:10,  1.73it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.74it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:18<00:09,  1.74it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:19<00:08,  1.73it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:19<00:08,  1.73it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:20<00:07,  1.73it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:20<00:06,  1.73it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:21<00:06,  1.73it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.73it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:22<00:05,  1.73it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:23<00:04,  1.73it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:23<00:04,  1.73it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:24<00:03,  1.72it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:24<00:02,  1.71it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:25<00:02,  1.72it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:25<00:01,  1.72it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:26<00:01,  1.72it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:27<00:00,  1.82it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.051417868584394455, 'eval_runtime': 28.2126, 'eval_samples_per_second': 6.912, 'eval_steps_per_second': 1.737, 'epoch': 6.99}\n 35%|██████████████                          | 682/1940 [24:09<38:25,  1.83s/it]\n100%|███████████████████████████████████████████| 49/49 [00:27<00:00,  2.22it/s]\u001b[A\n                                                                                \u001b[A/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.047, 'grad_norm': 16801.0546875, 'learning_rate': 1.4203894616265753e-05, 'epoch': 7.18}\n{'loss': 0.0437, 'grad_norm': 17554.6328125, 'learning_rate': 1.3631156930126004e-05, 'epoch': 7.69}\n 40%|████████████████                        | 780/1940 [27:11<30:44,  1.59s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:13,  3.60it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:18,  2.55it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:20,  2.21it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:21,  2.03it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:21,  1.96it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:22,  1.91it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:03<00:21,  1.87it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:21,  1.82it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:05<00:21,  1.82it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:21,  1.81it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:20,  1.81it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:06<00:19,  1.81it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:19,  1.78it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:07<00:18,  1.79it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:18,  1.80it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:08<00:17,  1.80it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.80it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:10<00:16,  1.79it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:10<00:16,  1.79it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:15,  1.80it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:11<00:15,  1.79it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:14,  1.79it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:12<00:13,  1.79it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:13,  1.79it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:13<00:12,  1.78it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.77it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:15<00:11,  1.77it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:15<00:11,  1.78it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.78it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:16<00:10,  1.77it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.77it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:17<00:09,  1.77it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:18<00:08,  1.75it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:19<00:07,  1.77it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:19<00:07,  1.78it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:20<00:06,  1.77it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:20<00:06,  1.78it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.78it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:21<00:05,  1.78it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:22<00:04,  1.78it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:22<00:03,  1.79it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:23<00:03,  1.78it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:24<00:02,  1.78it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:24<00:02,  1.78it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:25<00:01,  1.78it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:25<00:01,  1.78it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:26<00:00,  1.87it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.05180014669895172, 'eval_runtime': 27.379, 'eval_samples_per_second': 7.122, 'eval_steps_per_second': 1.79, 'epoch': 8.0}\n 40%|████████████████                        | 780/1940 [27:39<30:44,  1.59s/it]\n100%|███████████████████████████████████████████| 49/49 [00:26<00:00,  2.28it/s]\u001b[A\n                                                                                \u001b[A/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.044, 'grad_norm': 27592.2890625, 'learning_rate': 1.3058419243986255e-05, 'epoch': 8.21}\n{'loss': 0.0416, 'grad_norm': 19106.38671875, 'learning_rate': 1.2485681557846507e-05, 'epoch': 8.72}\n 45%|██████████████████                      | 877/1940 [30:39<31:14,  1.76s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:13,  3.60it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:18,  2.50it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:20,  2.16it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:21,  2.02it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:22,  1.94it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:22,  1.89it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:03<00:22,  1.85it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:21,  1.83it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:05<00:21,  1.82it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:21,  1.80it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:20,  1.78it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:06<00:20,  1.78it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:19,  1.79it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:07<00:18,  1.80it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:18,  1.80it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:08<00:17,  1.78it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.78it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:10<00:16,  1.78it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:10<00:16,  1.79it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:15,  1.79it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:11<00:15,  1.77it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:14,  1.79it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:12<00:14,  1.78it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:13,  1.78it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:14<00:12,  1.79it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.78it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:15<00:11,  1.77it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:15<00:11,  1.77it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.76it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:16<00:10,  1.77it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.77it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:17<00:09,  1.77it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:18<00:08,  1.77it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:19<00:07,  1.77it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:19<00:07,  1.76it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:20<00:06,  1.76it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:20<00:06,  1.77it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.78it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:21<00:05,  1.78it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:22<00:04,  1.78it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:23<00:03,  1.79it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:23<00:03,  1.78it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:24<00:02,  1.78it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:24<00:02,  1.78it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:25<00:01,  1.78it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:25<00:01,  1.75it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:26<00:00,  1.87it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.051916658878326416, 'eval_runtime': 27.4858, 'eval_samples_per_second': 7.095, 'eval_steps_per_second': 1.783, 'epoch': 8.99}\n 45%|██████████████████                      | 877/1940 [31:07<31:14,  1.76s/it]\n100%|███████████████████████████████████████████| 49/49 [00:26<00:00,  2.28it/s]\u001b[A\n                                                                                \u001b[A/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0435, 'grad_norm': 16895.44921875, 'learning_rate': 1.191294387170676e-05, 'epoch': 9.23}\n{'loss': 0.0417, 'grad_norm': 24392.017578125, 'learning_rate': 1.134020618556701e-05, 'epoch': 9.74}\n 50%|████████████████████                    | 975/1940 [34:09<25:36,  1.59s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:13,  3.60it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:18,  2.53it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:20,  2.18it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:21,  2.02it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:22,  1.93it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:22,  1.89it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:03<00:22,  1.85it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:21,  1.84it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:05<00:21,  1.82it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:20,  1.81it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:20,  1.80it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:06<00:20,  1.79it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:19,  1.79it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:07<00:18,  1.79it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:18,  1.80it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:08<00:17,  1.80it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.78it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:10<00:16,  1.78it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:10<00:16,  1.79it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:15,  1.78it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:11<00:15,  1.79it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:14,  1.79it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:12<00:13,  1.79it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:13,  1.79it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:13<00:12,  1.80it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.80it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:15<00:11,  1.79it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:15<00:11,  1.79it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.78it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:16<00:10,  1.77it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.78it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:17<00:08,  1.78it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:18<00:08,  1.78it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:19<00:07,  1.79it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:19<00:07,  1.78it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:20<00:06,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:20<00:06,  1.77it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.78it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:21<00:05,  1.78it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:22<00:04,  1.79it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:22<00:03,  1.79it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:23<00:03,  1.79it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:24<00:02,  1.80it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:24<00:02,  1.80it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:25<00:01,  1.80it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:25<00:01,  1.79it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:26<00:00,  1.89it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.051898133009672165, 'eval_runtime': 27.3299, 'eval_samples_per_second': 7.135, 'eval_steps_per_second': 1.793, 'epoch': 10.0}\n 50%|████████████████████                    | 975/1940 [34:36<25:36,  1.59s/it]\n100%|███████████████████████████████████████████| 49/49 [00:26<00:00,  2.28it/s]\u001b[A\n                                                                                \u001b[A/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0394, 'grad_norm': 20927.935546875, 'learning_rate': 1.0767468499427262e-05, 'epoch': 10.26}\n{'loss': 0.0397, 'grad_norm': 23259.146484375, 'learning_rate': 1.0194730813287515e-05, 'epoch': 10.77}\n 55%|█████████████████████▌                 | 1072/1940 [37:37<25:36,  1.77s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:12,  3.63it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:18,  2.51it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:20,  2.19it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:21,  2.03it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:22,  1.94it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:22,  1.89it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:03<00:22,  1.85it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:21,  1.83it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:05<00:21,  1.81it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:21,  1.79it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:20,  1.79it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:06<00:20,  1.79it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:19,  1.78it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:07<00:19,  1.76it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:18,  1.77it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:09<00:18,  1.77it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.77it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:10<00:16,  1.77it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:10<00:16,  1.77it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:15,  1.77it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:11<00:15,  1.77it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:14,  1.78it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:12<00:14,  1.78it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:13,  1.78it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:14<00:12,  1.79it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.79it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:15<00:11,  1.79it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:15<00:11,  1.79it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.79it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:16<00:10,  1.79it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.78it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:18<00:09,  1.74it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:18<00:08,  1.76it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:19<00:07,  1.76it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:19<00:07,  1.77it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:20<00:06,  1.76it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:20<00:06,  1.76it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.76it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:22<00:05,  1.74it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:22<00:04,  1.76it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:23<00:03,  1.77it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:23<00:03,  1.78it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:24<00:02,  1.78it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:24<00:02,  1.79it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:25<00:01,  1.80it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:25<00:01,  1.79it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:26<00:00,  1.88it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.05148625373840332, 'eval_runtime': 27.4797, 'eval_samples_per_second': 7.096, 'eval_steps_per_second': 1.783, 'epoch': 10.99}\n 55%|█████████████████████▌                 | 1072/1940 [38:05<25:36,  1.77s/it]\n100%|███████████████████████████████████████████| 49/49 [00:26<00:00,  2.29it/s]\u001b[A\n                                                                                \u001b[A/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0407, 'grad_norm': 32660.91015625, 'learning_rate': 9.621993127147768e-06, 'epoch': 11.28}\n{'loss': 0.0372, 'grad_norm': 22987.8828125, 'learning_rate': 9.04925544100802e-06, 'epoch': 11.79}\n 60%|███████████████████████▌               | 1170/1940 [41:06<20:33,  1.60s/it]\n  0%|                                                    | 0/49 [00:00<?, ?it/s]\u001b[A\n  4%|█▊                                          | 2/49 [00:00<00:13,  3.52it/s]\u001b[A\n  6%|██▋                                         | 3/49 [00:01<00:18,  2.49it/s]\u001b[A\n  8%|███▌                                        | 4/49 [00:01<00:20,  2.19it/s]\u001b[A\n 10%|████▍                                       | 5/49 [00:02<00:21,  2.02it/s]\u001b[A\n 12%|█████▍                                      | 6/49 [00:02<00:22,  1.92it/s]\u001b[A\n 14%|██████▎                                     | 7/49 [00:03<00:22,  1.88it/s]\u001b[A\n 16%|███████▏                                    | 8/49 [00:03<00:22,  1.83it/s]\u001b[A\n 18%|████████                                    | 9/49 [00:04<00:21,  1.83it/s]\u001b[A\n 20%|████████▊                                  | 10/49 [00:05<00:21,  1.81it/s]\u001b[A\n 22%|█████████▋                                 | 11/49 [00:05<00:21,  1.81it/s]\u001b[A\n 24%|██████████▌                                | 12/49 [00:06<00:20,  1.80it/s]\u001b[A\n 27%|███████████▍                               | 13/49 [00:06<00:20,  1.79it/s]\u001b[A\n 29%|████████████▎                              | 14/49 [00:07<00:19,  1.78it/s]\u001b[A\n 31%|█████████████▏                             | 15/49 [00:07<00:19,  1.78it/s]\u001b[A\n 33%|██████████████                             | 16/49 [00:08<00:18,  1.79it/s]\u001b[A\n 35%|██████████████▉                            | 17/49 [00:09<00:18,  1.77it/s]\u001b[A\n 37%|███████████████▊                           | 18/49 [00:09<00:17,  1.75it/s]\u001b[A\n 39%|████████████████▋                          | 19/49 [00:10<00:17,  1.76it/s]\u001b[A\n 41%|█████████████████▌                         | 20/49 [00:10<00:16,  1.77it/s]\u001b[A\n 43%|██████████████████▍                        | 21/49 [00:11<00:15,  1.77it/s]\u001b[A\n 45%|███████████████████▎                       | 22/49 [00:11<00:15,  1.77it/s]\u001b[A\n 47%|████████████████████▏                      | 23/49 [00:12<00:14,  1.76it/s]\u001b[A\n 49%|█████████████████████                      | 24/49 [00:12<00:14,  1.77it/s]\u001b[A\n 51%|█████████████████████▉                     | 25/49 [00:13<00:13,  1.77it/s]\u001b[A\n 53%|██████████████████████▊                    | 26/49 [00:14<00:13,  1.76it/s]\u001b[A\n 55%|███████████████████████▋                   | 27/49 [00:14<00:12,  1.75it/s]\u001b[A\n 57%|████████████████████████▌                  | 28/49 [00:15<00:12,  1.75it/s]\u001b[A\n 59%|█████████████████████████▍                 | 29/49 [00:15<00:11,  1.76it/s]\u001b[A\n 61%|██████████████████████████▎                | 30/49 [00:16<00:10,  1.77it/s]\u001b[A\n 63%|███████████████████████████▏               | 31/49 [00:16<00:10,  1.76it/s]\u001b[A\n 65%|████████████████████████████               | 32/49 [00:17<00:09,  1.77it/s]\u001b[A\n 67%|████████████████████████████▉              | 33/49 [00:18<00:09,  1.78it/s]\u001b[A\n 69%|█████████████████████████████▊             | 34/49 [00:18<00:08,  1.78it/s]\u001b[A\n 71%|██████████████████████████████▋            | 35/49 [00:19<00:07,  1.77it/s]\u001b[A\n 73%|███████████████████████████████▌           | 36/49 [00:19<00:07,  1.77it/s]\u001b[A\n 76%|████████████████████████████████▍          | 37/49 [00:20<00:06,  1.78it/s]\u001b[A\n 78%|█████████████████████████████████▎         | 38/49 [00:20<00:06,  1.77it/s]\u001b[A\n 80%|██████████████████████████████████▏        | 39/49 [00:21<00:05,  1.79it/s]\u001b[A\n 82%|███████████████████████████████████        | 40/49 [00:22<00:05,  1.79it/s]\u001b[A\n 84%|███████████████████████████████████▉       | 41/49 [00:22<00:04,  1.78it/s]\u001b[A\n 86%|████████████████████████████████████▊      | 42/49 [00:23<00:03,  1.79it/s]\u001b[A\n 88%|█████████████████████████████████████▋     | 43/49 [00:23<00:03,  1.77it/s]\u001b[A\n 90%|██████████████████████████████████████▌    | 44/49 [00:24<00:02,  1.78it/s]\u001b[A\n 92%|███████████████████████████████████████▍   | 45/49 [00:24<00:02,  1.79it/s]\u001b[A\n 94%|████████████████████████████████████████▎  | 46/49 [00:25<00:01,  1.80it/s]\u001b[A\n 96%|█████████████████████████████████████████▏ | 47/49 [00:25<00:01,  1.79it/s]\u001b[A\n 98%|██████████████████████████████████████████ | 48/49 [00:26<00:00,  1.88it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.051810748875141144, 'eval_runtime': 27.5362, 'eval_samples_per_second': 7.082, 'eval_steps_per_second': 1.779, 'epoch': 12.0}\n 60%|███████████████████████▌               | 1170/1940 [41:34<20:33,  1.60s/it]\n100%|███████████████████████████████████████████| 49/49 [00:26<00:00,  2.29it/s]\u001b[A\n{'train_runtime': 2497.571, 'train_samples_per_second': 6.23, 'train_steps_per_second': 0.777, 'train_loss': 0.11224941448268727, 'epoch': 12.0}\n 60%|███████████████████████▌               | 1170/1940 [41:37<27:23,  2.13s/it]\n✅ LayoutLMv3 fine-tuning complete (smart entity labeling enabled).\n/usr/bin/python3: Error while finding module specification for 'receipt_ie.models.training.train_layoutlmv3.py' (ModuleNotFoundError: __path__ attribute not found on 'receipt_ie.models.training.train_layoutlmv3' while trying to find 'receipt_ie.models.training.train_layoutlmv3.py'). Try using 'receipt_ie.models.training.train_layoutlmv3' instead of 'receipt_ie.models.training.train_layoutlmv3.py' as the module name.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### Upload Trained Model to Hugging Face","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import HfApi, upload_folder, create_repo\nfrom kaggle_secrets import UserSecretsClient\n\n# --- Loading Hugging Face token ---\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n\n# --- Repo details ---\nrepo_id = \"muhammadummerrr/layoutlmv3-receipt-epochs-20\"\n\n# --- Initialize API and create repo ---\napi = HfApi()\napi.create_repo(repo_id=repo_id, private=False, token=hf_token, exist_ok=True)\n\n# --- Upload fine-tuned model folder ---\nupload_folder(\n    folder_path=\"/kaggle/temp/outputs_layoutlmv3/final_model\",\n    repo_id=repo_id,\n    token=hf_token,\n)\n\nprint(f\"Uploaded fine-tuned LayoutLMv3 model to https://huggingface.co/{repo_id}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T18:17:42.996448Z","iopub.execute_input":"2025-10-19T18:17:42.996806Z","iopub.status.idle":"2025-10-19T18:17:47.426977Z","shell.execute_reply.started":"2025-10-19T18:17:42.996779Z","shell.execute_reply":"2025-10-19T18:17:47.425865Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### Augment Watermark dataset","metadata":{}},{"cell_type":"code","source":"!python -m src.receipt_ie.models.watermark.augment_watermark_dataset \\\n  --input_dir /kaggle/input/wm-dataset/watermark-dataset \\\n  --output_dir /kaggle/working/receipt-watermark-augmented \\\n  --split_ratio 0.8 \\\n  --aug_per_image 3\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T22:22:05.991263Z","iopub.execute_input":"2025-10-19T22:22:05.991958Z","iopub.status.idle":"2025-10-19T22:24:23.440770Z","shell.execute_reply.started":"2025-10-19T22:22:05.991928Z","shell.execute_reply":"2025-10-19T22:24:23.440071Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/Intelligent-Receipt/src/receipt_ie/models/watermark/augment_watermark_dataset.py:40: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n  A.ImageCompression(quality_lower=85, quality_upper=100, p=0.4),\n/kaggle/working/Intelligent-Receipt/src/receipt_ie/models/watermark/augment_watermark_dataset.py:42: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n  A.GaussNoise(var_limit=(5, 20), p=0.3),\n📸 Processing clean -> train (68 images)...\n100%|███████████████████████████████████████████| 68/68 [00:32<00:00,  2.08it/s]\n📸 Processing clean -> test (17 images)...\n100%|███████████████████████████████████████████| 17/17 [00:05<00:00,  2.97it/s]\n📸 Processing watermark -> train (68 images)...\n100%|███████████████████████████████████████████| 68/68 [01:04<00:00,  1.05it/s]\n📸 Processing watermark -> test (17 images)...\n100%|███████████████████████████████████████████| 17/17 [00:26<00:00,  1.54s/it]\n Augmented dataset created at: /kaggle/working/receipt-watermark-augmented\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Train ViT Watermark Detector","metadata":{}},{"cell_type":"code","source":"!python -m src.receipt_ie.models.watermark.train_vit_watermark_classifier \\\n  --data_root /kaggle/working/receipt-watermark-augmented \\\n  --out_dir /kaggle/working/wm_vit_output \\\n  --epochs 10 \\\n  --batch 32 \\\n  --lr 5e-5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T22:27:28.884836Z","iopub.execute_input":"2025-10-19T22:27:28.885463Z","iopub.status.idle":"2025-10-19T22:53:27.291903Z","shell.execute_reply.started":"2025-10-19T22:27:28.885431Z","shell.execute_reply":"2025-10-19T22:53:27.290943Z"}},"outputs":[{"name":"stdout","text":"2025-10-19 22:27:33.404425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760912853.427243     153 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760912853.434097     153 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nFound: train=544 val=136\npreprocessor_config.json: 100%|█████████████████| 160/160 [00:00<00:00, 937kB/s]\nconfig.json: 100%|█████████████████████████████| 502/502 [00:00<00:00, 3.74MB/s]\nmodel.safetensors: 100%|██████████████████████| 346M/346M [00:01<00:00, 205MB/s]\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nClass counts train: [272, 272]  -> class_weights: [1. 1.]\n/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n🚀 Training start\n 10%|████▍                                       | 9/90 [02:10<12:35,  9.33s/it]\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n 67%|██████████████████████████████               | 2/3 [00:00<00:00,  5.50it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.5248839259147644, 'eval_accuracy': 0.8602941176470589, 'eval_precision': 0.9454545454545454, 'eval_recall': 0.7647058823529411, 'eval_f1': 0.8455284552845529, 'eval_runtime': 23.8658, 'eval_samples_per_second': 5.699, 'eval_steps_per_second': 0.126, 'epoch': 1.0}\n 10%|████▍                                       | 9/90 [02:34<12:35,  9.33s/it]\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  6.61it/s]\u001b[A\n 20%|████████▌                                  | 18/90 [04:41<09:25,  7.86s/it]\u001b[A\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n 67%|██████████████████████████████               | 2/3 [00:00<00:00,  4.64it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.3083944320678711, 'eval_accuracy': 0.9264705882352942, 'eval_precision': 1.0, 'eval_recall': 0.8529411764705882, 'eval_f1': 0.9206349206349206, 'eval_runtime': 23.755, 'eval_samples_per_second': 5.725, 'eval_steps_per_second': 0.126, 'epoch': 2.0}\n 20%|████████▌                                  | 18/90 [05:05<09:25,  7.86s/it]\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.80it/s]\u001b[A\n 30%|████████████▉                              | 27/90 [07:15<07:17,  6.94s/it]\u001b[A\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n 67%|██████████████████████████████               | 2/3 [00:00<00:00,  4.71it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.22945791482925415, 'eval_accuracy': 0.9191176470588235, 'eval_precision': 0.9523809523809523, 'eval_recall': 0.8823529411764706, 'eval_f1': 0.916030534351145, 'eval_runtime': 23.7269, 'eval_samples_per_second': 5.732, 'eval_steps_per_second': 0.126, 'epoch': 3.0}\n 30%|████████████▉                              | 27/90 [07:39<07:17,  6.94s/it]\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.85it/s]\u001b[A\n 40%|█████████████████▏                         | 36/90 [09:30<06:07,  6.81s/it]\u001b[A\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n 67%|██████████████████████████████               | 2/3 [00:00<00:00,  4.66it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.18148736655712128, 'eval_accuracy': 0.9411764705882353, 'eval_precision': 1.0, 'eval_recall': 0.8823529411764706, 'eval_f1': 0.9375, 'eval_runtime': 23.7781, 'eval_samples_per_second': 5.72, 'eval_steps_per_second': 0.126, 'epoch': 4.0}\n 40%|█████████████████▏                         | 36/90 [09:54<06:07,  6.81s/it]\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.81it/s]\u001b[A\n 50%|█████████████████████▌                     | 45/90 [12:15<07:22,  9.82s/it]\u001b[A\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n 67%|██████████████████████████████               | 2/3 [00:00<00:00,  4.63it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.15533572435379028, 'eval_accuracy': 0.9338235294117647, 'eval_precision': 0.9836065573770492, 'eval_recall': 0.8823529411764706, 'eval_f1': 0.9302325581395349, 'eval_runtime': 23.9335, 'eval_samples_per_second': 5.682, 'eval_steps_per_second': 0.125, 'epoch': 5.0}\n 50%|█████████████████████▌                     | 45/90 [12:38<07:22,  9.82s/it]\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.85it/s]\u001b[A\n{'loss': 0.2283, 'grad_norm': 25885.64453125, 'learning_rate': 2.2222222222222223e-05, 'epoch': 5.56}\n 60%|█████████████████████████▊                 | 54/90 [14:48<05:24,  9.02s/it]\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n 67%|██████████████████████████████               | 2/3 [00:00<00:00,  4.49it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.13946998119354248, 'eval_accuracy': 0.9485294117647058, 'eval_precision': 0.9692307692307692, 'eval_recall': 0.9264705882352942, 'eval_f1': 0.9473684210526315, 'eval_runtime': 24.0287, 'eval_samples_per_second': 5.66, 'eval_steps_per_second': 0.125, 'epoch': 6.0}\n 60%|█████████████████████████▊                 | 54/90 [15:12<05:24,  9.02s/it]\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.61it/s]\u001b[A\n 70%|██████████████████████████████             | 63/90 [17:17<04:09,  9.25s/it]\u001b[A\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n 67%|██████████████████████████████               | 2/3 [00:00<00:00,  4.60it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.14602123200893402, 'eval_accuracy': 0.9485294117647058, 'eval_precision': 0.9841269841269841, 'eval_recall': 0.9117647058823529, 'eval_f1': 0.9465648854961832, 'eval_runtime': 24.0427, 'eval_samples_per_second': 5.657, 'eval_steps_per_second': 0.125, 'epoch': 7.0}\n 70%|██████████████████████████████             | 63/90 [17:41<04:09,  9.25s/it]\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.78it/s]\u001b[A\n 80%|██████████████████████████████████▍        | 72/90 [19:51<02:39,  8.89s/it]\u001b[A\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n 67%|██████████████████████████████               | 2/3 [00:00<00:00,  4.67it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.11874567717313766, 'eval_accuracy': 0.9485294117647058, 'eval_precision': 0.9552238805970149, 'eval_recall': 0.9411764705882353, 'eval_f1': 0.9481481481481482, 'eval_runtime': 23.8769, 'eval_samples_per_second': 5.696, 'eval_steps_per_second': 0.126, 'epoch': 8.0}\n 80%|██████████████████████████████████▍        | 72/90 [20:14<02:39,  8.89s/it]\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.85it/s]\u001b[A\n 90%|██████████████████████████████████████▋    | 81/90 [22:20<01:18,  8.67s/it]\u001b[A\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n 67%|██████████████████████████████               | 2/3 [00:00<00:00,  4.48it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.15231512486934662, 'eval_accuracy': 0.9485294117647058, 'eval_precision': 0.9841269841269841, 'eval_recall': 0.9117647058823529, 'eval_f1': 0.9465648854961832, 'eval_runtime': 24.4592, 'eval_samples_per_second': 5.56, 'eval_steps_per_second': 0.123, 'epoch': 9.0}\n 90%|██████████████████████████████████████▋    | 81/90 [22:45<01:18,  8.67s/it]\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.69it/s]\u001b[A\n100%|███████████████████████████████████████████| 90/90 [24:48<00:00,  7.43s/it]\u001b[A\n  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n 67%|██████████████████████████████               | 2/3 [00:00<00:00,  4.71it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 0.1526617407798767, 'eval_accuracy': 0.9485294117647058, 'eval_precision': 0.9841269841269841, 'eval_recall': 0.9117647058823529, 'eval_f1': 0.9465648854961832, 'eval_runtime': 24.3593, 'eval_samples_per_second': 5.583, 'eval_steps_per_second': 0.123, 'epoch': 10.0}\n100%|███████████████████████████████████████████| 90/90 [25:14<00:00,  7.43s/it]\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.85it/s]\u001b[A\n{'train_runtime': 1517.7731, 'train_samples_per_second': 3.584, 'train_steps_per_second': 0.059, 'train_loss': 0.13434142470359803, 'epoch': 10.0}\n100%|███████████████████████████████████████████| 90/90 [25:17<00:00, 16.86s/it]\n✅ Training complete\n100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.53it/s]\n\n[VAL]  acc=0.9485  prec=0.9552  rec=0.9412  f1=0.9481\nConfusion matrix [rows=true clean, watermarked]:\n [[65  3]\n [ 4 64]]\n\n🔎 Demo prediction on X51005301661_aug3.jpg -> {'clean': 0.9769408106803894, 'watermarked': 0.023059198632836342}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Upload ViT Model to Hugging Face","metadata":{}},{"cell_type":"code","source":"# --- Repo details for the ViT watermark model ---\napi = HfApi()\nrepo_id = \"muhammadummerrr/vit-water-mark-detector-v1-extended\"\napi.create_repo(repo_id=repo_id, private=False, token=hf_token, exist_ok=True)\nupload_folder(\n    folder_path=\"/kaggle/working/wm_vit_advanced_out\",  # your model output folder\n    repo_id=repo_id,\n    token=hf_token,\n)\n\nprint(f\"Uploaded watermark classifier to https://huggingface.co/{repo_id}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git pull","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T12:54:52.668892Z","iopub.execute_input":"2025-10-20T12:54:52.669215Z","iopub.status.idle":"2025-10-20T12:54:53.096920Z","shell.execute_reply.started":"2025-10-20T12:54:52.669191Z","shell.execute_reply":"2025-10-20T12:54:53.096188Z"}},"outputs":[{"name":"stdout","text":"remote: Enumerating objects: 11, done.\u001b[K\nremote: Counting objects: 100% (11/11), done.\u001b[K\nremote: Compressing objects: 100% (4/4), done.\u001b[K\nremote: Total 6 (delta 1), reused 6 (delta 1), pack-reused 0 (from 0)\u001b[K\nUnpacking objects: 100% (6/6), 1.91 KiB | 980.00 KiB/s, done.\nFrom https://github.com/muhammadummerr/Intelligent-Receipt\n   f6d2269..93f5272  main       -> origin/main\nUpdating f6d2269..93f5272\nFast-forward\n src/receipt_ie/pipelines/run_pipeline.py | 38 \u001b[32m+++++++++++++++++++\u001b[m\u001b[31m-------------\u001b[m\n 1 file changed, 23 insertions(+), 15 deletions(-)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### End-to-End Inference Pipeline","metadata":{}},{"cell_type":"code","source":"!python -m src.receipt_ie.pipelines.run_pipeline \\\n  --image_path /kaggle/input/receipt-dataset/test/img/X51005587261.jpg \\\n  --box_dir /kaggle/input/receipt-dataset/test/box \\\n  --out_path /kaggle/working/X51005230605_result.json \\\n  --provider groq \\\n  --model llama-3.3-70b-versatile\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T13:13:41.425867Z","iopub.execute_input":"2025-10-20T13:13:41.426181Z","iopub.status.idle":"2025-10-20T13:13:57.839061Z","shell.execute_reply.started":"2025-10-20T13:13:41.426130Z","shell.execute_reply":"2025-10-20T13:13:57.838170Z"}},"outputs":[{"name":"stdout","text":"2025-10-20 13:13:45.965366: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760966025.989811     567 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760966025.997502     567 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n🔍 Processing: X51005587261.jpg\n🛡️ Checking for watermarks or tampering...\n📄 Found 1 valid receipts for inference.\n/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n🧾 Extracted: {'company': 'CHOP', 'date': '23/03/17', 'address': 'COMPANY', 'total': '30.00'}\n[INFO] LLM initialized — provider=groq, model=llama-3.3-70b-versatile\n✅ Final corrected output ready.\n\n🎉 Saved final result to /kaggle/working/X51005230605_result.json\n{\n  \"company\": \"CHOP YEW LIAN\",\n  \"date\": \"23/03/17\",\n  \"address\": \"LOT PT 5121 PER KLANG SEK 27 40000 SHAH ALAM SELANGOR\",\n  \"total\": \"31.70\",\n  \"agent_comment\": \"Corrected company name, address, and total amount to include GST.\"\n}\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"/kaggle/input/receipt-dataset/test/img/X51005447844.jpg","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}