# ğŸ§¾ Intelligent Receipt â€” End-to-End AI for Receipt Understanding  

**Intelligent Receipt** is a unified AI system that automates receipt understanding using:  
- ğŸ§  **LayoutLMv3** for document field extraction  
- ğŸ–¼ï¸ **ViT** for watermark/tampering detection  
- ğŸ¤– **LLM reasoning (Groq / OpenAI / Mistral)** for validation and correction  

It can automatically detect fake receipts, extract structured information, and produce clean, human-readable JSON outputs.  

---

## ğŸ” Key Features  

- ğŸ§© **Hybrid Pipeline:** Combines computer vision, document AI, and reasoning in one workflow  
- ğŸ§¾ **Field Extraction:** Extracts `company`, `date`, `address`, and `total` using LayoutLMv3  
- ğŸ•µï¸ **Watermark Detection:** ViT-based classifier detects tampered or fake receipts  
- ğŸ§  **LLM Reasoning:** Uses Groq / GPT / Mistral to refine and validate extracted fields  
- â˜ï¸ **Hugging Face Integration:** Upload and reuse models seamlessly  
- âš™ï¸ **Modular Architecture:** Independent training, inference, and reasoning components  

---

## ğŸ§© System Overview  

```text
Receipt Image
   â”‚
   â”œâ”€â”€â–º ViT Watermark Detector
   â”‚        â””â”€â”€ Rejects tampered/fake receipts
   â”‚
   â”œâ”€â”€â–º LayoutLMv3 Extractor
   â”‚        â””â”€â”€ Extracts text regions and entity tags
   â”‚
   â”œâ”€â”€â–º LLM Reasoning Agent
   â”‚        â””â”€â”€ Validates and corrects structured fields
   â”‚
   â””â”€â”€â–º Final JSON Output

---

## ğŸ“¦ Datasets Used
Receipt-dataset â†’ (Provided by the Unikrew Solution)
link: https://unikrew-my.sharepoint.com/:u:/p/uzair_mughal/Eco5MROMYQlHm2mGgAD2PCABeFhdtuEvBBb2g-lGXtTPew?e=LGImL7

Watermark-dataset â†’ Custom-created by blurring or overlaying different regions of real receipts.
link: https://drive.google.com/drive/folders/1JVLB1lK9vLtUr_VkuxvYq7zauB1MB1RT?usp=drive_link
Note:
For real-world use, watermark types can be extended to include multiple tampering and forgery styles and increasing the dataset size.

---

## ğŸ§° Tech Stack
| Category      | Tools / Frameworks                     |
| ------------- | -------------------------------------- |
| Document AI   | LayoutLMv3 (Hugging Face Transformers) |
| Vision        | ViT Base (Image Classification)        |
| LLM Reasoning | Groq / OpenAI GPT / Mistral            |
| OCR           | EasyOCR                                |
| Hosting       | Hugging Face Hub                       |
| Training      | PyTorch + Accelerate                   |
| Environment   | Kaggle / Local GPU                     |

---


## âš™ï¸ Setup and Installation
Clone the repository and install dependencies:

```
    git clone https://github.com/muhammadummerr/Intelligent-Receipt.git
    cd Intelligent-Receipt
    pip install -r requirements.txt
    export PYTHONPATH=./src
```

If using Kaggle, simply add:

```
    %env PYTHONPATH=./src
``` 

## ğŸ§  Training the Models
# ğŸ§¾ LayoutLMv3 â€” Field Extraction

```
    python -m src.receipt_ie.models.training.train_layoutlmv3

```
After training, the model will be saved at:

/kaggle/temp/outputs_layoutlmv3/final_model/

## ğŸ•µï¸ ViT â€” Watermark Detection
# 1ï¸âƒ£ Augment Dataset

```
    python -m src.receipt_ie.models.watermark.augment_watermark_dataset \
    --input_dir /kaggle/input/wm-dataset/watermark-dataset \
    --output_dir /kaggle/working/receipt-watermark-augmented \
    --split_ratio 0.8 --aug_per_image 3
```

# 2ï¸âƒ£ Train ViT Classifier

```
    python -m src.receipt_ie.models.watermark.train_vit_watermark_classifier \
    --data_root /kaggle/working/receipt-watermark-augmented \
    --out_dir /kaggle/working/wm_vit_output \
    --epochs 10 --batch 32 --lr 5e-5
```

# â˜ï¸ Upload Models to Hugging Face

```
    from huggingface_hub import HfApi, upload_folder
    from kaggle_secrets import UserSecretsClient

    user_secrets = UserSecretsClient()
    hf_token = user_secrets.get_secret("HUGGINGFACE_TOKEN")

    api = HfApi()
    repo_id = "muhammadummerrr/layoutlmv3-receipt-epochs-20"
    api.create_repo(repo_id=repo_id, private=False, token=hf_token, exist_ok=True)

    upload_folder(
        folder_path="/kaggle/temp/outputs_layoutlmv3/final_model",
        repo_id=repo_id,
        token=hf_token,
)
```

âœ… Uploaded models:

LayoutLMv3 Receipt Model

ViT Watermark Detector

## Running the Full Inference Pipeline

Once both models are trained and uploaded, run:

```
    python -m src.receipt_ie.pipelines.run_pipeline \
    --image_path /kaggle/input/receipt-dataset/test/img/X51005587261.jpg \
    --box_dir /kaggle/input/receipt-dataset/test/box \
    --out_path /kaggle/working/X51005230605_result.json \
    --provider groq \
    --model llama-3.3-70b-versatile
```

Example output:

{
  "company": "CHAY SEAFOOD RESTAURANT",
  "date": "15/01/2019",
  "address": "JALAN HARMONI 3/2, TAMAN DESA HARMONI, 81100 JOHOR BAHRU",
  "total": "45.80",
  "agent_comment": "Validated and normalized fields using OCR and LLM reasoning."
}

ğŸ§© Project Structure
   
+---configs
+---data
Âª   +---processed
Âª   +---raw
Âª   +---samples
+---models
Âª   +---pretrained
+---notebooks
Âª       intelligent-receipt-pipeline.ipynb    â† main training & inference notebook
Âª       
+---src
Âª   +---receipt_ie
Âª       +---data
Âª       Âª       boxes.py
Âª       Âª       dataset_infer.py
Âª       Âª       text.py
Âª       Âª       __init__.py
Âª       Âª       
Âª       +---infer
Âª       +---models
Âª       Âª   +---training
Âª       Âª   Âª   Âª   train_layoutlmv3.py
Âª       Âª   Âª   Âª   __init__.py
Âª       Âª   Âª   Âª   
Âª       Âª   Âª   +---helpers
Âª       Âª   Âª           augmentations.py
Âª       Âª   Âª           data_utils.py
Âª       Âª   Âª           entity_utils.py
Âª       Âª   Âª           
Âª       Âª   +---watermark
Âª       Âª       Âª   augment_watermark_dataset.py
Âª       Âª       Âª   train_vit_watermark_classifier.py
Âª       Âª       Âª   __init__.py
Âª       Âª       Âª   
Âª       Âª       +---utils
Âª       Âª               watermark_filter.py
Âª       Âª               wm_dataset.py
Âª       Âª               wm_data_utils.py
Âª       Âª               __init__.py
Âª       Âª               
Âª       +---pipelines
Âª       Âª       run_pipeline.py
Âª       Âª       __init.py
Âª       Âª       
Âª       +---utils
Âª               decode.py
Âª               llm_client.py
Âª               postproc.py
Âª               __init__.py
Âª               
+---tests


## ğŸ“ˆ Results:

| Field   | Extracted               | Ground Truth | Notes                           |
| ------- | ----------------------- | ------------ | ------------------------------- |
| Company | CHAY SEAFOOD RESTAURANT | âœ…            | Reconstructed                  |
| Date    | 15/01/2019              | âœ…            | Normalized                     |
| Address | JALAN HARMONI, JOHOR    | âœ…            | Reconstructed                  |
| Total   | 45.80                   | âœ…            | Verified using reasoning agent |



## â–¶ï¸ Quick Start (Notebook)

To run the full training and reasoning pipeline:

Open notebooks/intelligent_receipt_pipeline.ipynb

Execute all cells sequentially

Adjust dataset paths (for receipt-dataset and watermark-dataset) as per your environment


## ğŸ¥ Demo  

<video src="assets/demo.mp4" width="640" controls></video>

> ğŸ•’ Duration: 42 seconds  
> ğŸ“ Shows: LayoutLMv3 + ViT + LLM reasoning end-to-end inference

---
## ğŸ‘¤ Author

Muhammad Umer Farooq
ğŸ“ Bachelorâ€™s in Computer Science â€” Namal University
ğŸ“š Research Focus: Computer Vision, Document AI, and LLM Reasoning
